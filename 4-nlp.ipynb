{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "One of my objectives was to predict from the description how well the movie was going to be received.\n",
    "To do that I need to work with the ``description`` column as input, and change the ``rating`` column into a boolean one where True is over 5 of valoration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data\\imdb_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.sample(100, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approved(rating):\n",
    "    if rating >= 5.0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     33941\n",
       "False     4917\n",
       "Name: rating, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rating_bool = data.rating.map(approved)\n",
    "rating_bool.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = data[['genres', 'description']]\n",
    "descriptions = sample.description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(s):\n",
    "    \"\"\"\n",
    "    Cleans up numbers, URLs, and special characters from a string.\n",
    "\n",
    "    Args:\n",
    "        s: The string to be cleaned up.\n",
    "\n",
    "    Returns:\n",
    "        A string that has been cleaned up.\n",
    "    \"\"\"\n",
    "    reg_url = '(?:(?:https?|ftp):\\/\\/)?[\\w\\/\\-?=%.]+\\.[\\w\\/\\-&?=%.]+'\n",
    "    reg_sp  = '[^A-Za-z ]'\n",
    "\n",
    "    s = re.sub(reg_url,'',s) \n",
    "\n",
    "    s = re.sub(reg_sp,' ',s) \n",
    "\n",
    "    return s\n",
    "\n",
    "def tokenize(s):\n",
    "    \"\"\"\n",
    "    Tokenize a string.\n",
    "\n",
    "    Args:\n",
    "        s: String to be tokenized.\n",
    "\n",
    "    Returns:\n",
    "        A list of words as the result of tokenization.\n",
    "    \"\"\"\n",
    "    s = word_tokenize(s)\n",
    "\n",
    "    return s\n",
    "\n",
    "def stem_and_lemmatize(l):\n",
    "    \"\"\"\n",
    "    Perform stemming and lemmatization on a list of words.\n",
    "\n",
    "    Args:\n",
    "        l: A list of strings.\n",
    "\n",
    "    Returns:\n",
    "        A list of strings after being stemmed and lemmatized.\n",
    "    \"\"\"\n",
    "    ps = PorterStemmer() #I'm not convinced these go here\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "    list = [lemmatizer.lemmatize(ps.stem(word)) for word in l]\n",
    "\n",
    "    for word in l:\n",
    "        word = ps.stem(word)\n",
    "        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "    return list\n",
    "\n",
    "def remove_stopwords(l):\n",
    "    \"\"\"\n",
    "    Remove English stopwords from a list of strings.\n",
    "\n",
    "    Args:\n",
    "        l: A list of strings.\n",
    "\n",
    "    Returns:\n",
    "        A list of strings after stop words are removed.\n",
    "    \"\"\"\n",
    "    clean_list = [word for word in l if not word in stopwords.words()]\n",
    "\n",
    "    return clean_list\n",
    "\n",
    "def full_process(s):\n",
    "    '''\n",
    "    Args:\n",
    "        s: the string to process\n",
    "\n",
    "    Returns:\n",
    "        The list of words after removing the stopwords\n",
    "    '''\n",
    "    # s = clean_up(s)\n",
    "    l = tokenize(s)\n",
    "    l = stem_and_lemmatize(l)\n",
    "    clean_list = remove_stopwords(l)\n",
    "\n",
    "    return clean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19686    [six, youth, crimin, chosen, particip, social,...\n",
       "953      [privat, detect, hire, three, kidnap, wealthi,...\n",
       "27625    [ireland, fli, saucer, full, alien, land, farm...\n",
       "1416     [armi, send, andi, thoma, pose, renegad, find,...\n",
       "38319    [anxieti, attack, new, encount, forc, mari, re...\n",
       "1731     [sli, busi, manag, wacki, friend, two, opera, ...\n",
       "33109    [loaf, countri, boy, arriv, athen, studi, inst...\n",
       "7954     [mani, version, shakespear, masterpiec, none, ...\n",
       "18924    [th, centuri, ukrain, polish, overlord, ukrain...\n",
       "21617    [show, set, circu, backdrop, focus, littlechap...\n",
       "35369    [housewif, despis, societi, health, look, susp...\n",
       "12639    [life, career, heavyweight, champion, joe, lou...\n",
       "3168     [dr, molnac, hi, music, troup, begg, manag, mi...\n",
       "16111    [militari, school, cadet, boon, win, date, fre...\n",
       "26766    [cotter, qv, sioux, indian, whose, life, tragi...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = descriptions.apply(full_process) #full\n",
    "tokens[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19686    [six, youth, crimin, chosen, particip, social,...\n",
       "953      [privat, detect, hire, three, kidnap, wealthi,...\n",
       "27625    [ireland, fli, saucer, full, alien, land, farm...\n",
       "1416     [armi, send, andi, thoma, pose, renegad, find,...\n",
       "38319    [anxieti, attack, new, encount, forc, mari, re...\n",
       "1731     [sli, busi, manag, wacki, friend, two, opera, ...\n",
       "33109    [loaf, countri, boy, arriv, athen, studi, inst...\n",
       "7954     [mani, version, shakespear, masterpiec, none, ...\n",
       "18924    [th, centuri, ukrain, polish, overlord, ukrain...\n",
       "21617    [show, set, circu, backdrop, focus, littlechap...\n",
       "35369    [housewif, despis, societi, health, look, susp...\n",
       "12639    [life, career, heavyweight, champion, joe, lou...\n",
       "3168     [dr, molnac, hi, music, troup, begg, manag, mi...\n",
       "16111    [militari, school, cadet, boon, win, date, fre...\n",
       "26766    [cotter, qv, sioux, indian, whose, life, tragi...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = descriptions.apply(full_process) # no stopwords\n",
    "tokens[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19686    [six, youth, crimin, chosen, particip, social,...\n",
       "953      [privat, detect, hire, three, kidnap, wealthi,...\n",
       "27625    [ireland, fli, saucer, full, alien, land, farm...\n",
       "1416     [armi, send, andi, thoma, pose, renegad, find,...\n",
       "38319    [anxieti, attack, new, encount, forc, mari, re...\n",
       "1731     [sli, busi, manag, wacki, friend, two, opera, ...\n",
       "33109    [loaf, countri, boy, arriv, athen, studi, inst...\n",
       "7954     [mani, version, shakespear, masterpiec, none, ...\n",
       "18924    [th, centuri, ukrain, polish, overlord, ukrain...\n",
       "21617    [show, set, circu, backdrop, focus, littlechap...\n",
       "35369    [housewif, despis, societi, health, look, susp...\n",
       "12639    [life, career, heavyweight, champion, joe, lou...\n",
       "3168     [dr, molnac, hi, music, troup, begg, manag, mi...\n",
       "16111    [militari, school, cadet, boon, win, date, fre...\n",
       "26766    [cotter, qv, sioux, indian, whose, life, tragi...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = descriptions.apply(full_process) # no regex\n",
    "tokens[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38858, 8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f23c331dcc0e959a18d97d72b32723b8e8fefc4a029dc171226f15b89161c30"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
