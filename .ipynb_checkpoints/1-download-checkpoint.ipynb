{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Data gathering\n",
    "\n",
    "I am going to use as the main source of info the dataset offered by IMDB in https://datasets.imdbws.com/  \n",
    "Specifically, I choose the file **title.basics.tsv.gz**, which has this structure according to the documentation:\n",
    "\n",
    "* tconst (string) - alphanumeric unique identifier of the title\n",
    "* titleType (string) – the type/format of the title (e.g. movie, short, tvseries, tvepisode, video, etc)\n",
    "* primaryTitle (string) – the more popular title / the title used by the filmmakers on promotional materials at the point of release\n",
    "* originalTitle (string) - original title, in the original language\n",
    "* isAdult (boolean) - 0: non-adult title; 1: adult title\n",
    "* startYear (YYYY) – represents the release year of a title. In the case of TV Series, it is the series start year\n",
    "* endYear (YYYY) – TV Series end year. ‘\\N’ for all other title types\n",
    "* runtimeMinutes – primary runtime of the title, in minutes\n",
    "* genres (string array) – includes up to three genres associated with the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "basics = pd.read_csv('data/data.tsv', sep='\\t')\n",
    "basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basics.titleType.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amount of items is too big, so I will keep only the movies, with more than 600k items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basics_movies = basics.loc[basics['titleType'] == 'movie']\n",
    "basics_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But that is not enough, I need more information, mainly the description, and for that I will use the CinemaGoer library (https://cinemagoer.github.io):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cinemagoer\n",
    "from imdb import Cinemagoer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_IMDB_movie_data(movie_ID=''):\n",
    "    \"\"\"\n",
    "    Returns the following information of a title in a list form:\n",
    "        IMDB rating\n",
    "        genres\n",
    "        MPAA rating\n",
    "        Description\n",
    "        maybe later: movie_title='',\n",
    "    \"\"\"\n",
    "    if movie_ID=='':\n",
    "        raise Exception(\"No title or ID provided\")\n",
    "    \n",
    "    movie_ID = movie_ID.replace('t', '')\n",
    "    \n",
    "    try:\n",
    "        movie = ia.get_movie(movie_ID)\n",
    "    except:\n",
    "        return (pd.NA,pd.NA,pd.NA,pd.NA,pd.NA)\n",
    "\n",
    "    try:\n",
    "        rating = movie.data['rating']\n",
    "        # result['rating'] = movie.data['rating']\n",
    "    except:\n",
    "        rating = pd.NA\n",
    "        # result['rating'] = pd.NA\n",
    "\n",
    "    try:\n",
    "        # result['genres'] = 0\n",
    "        genres = [genre.lower() for genre in movie.data['genres']]\n",
    "    except:\n",
    "        # result['genres'] = pd.NA\n",
    "        genres = pd.NA\n",
    "\n",
    "    try:\n",
    "        # result['mpaa'] = [c.split(':')[1] for c in movie.data['certificates'] if (c.startswith('United States') or 'USA' in c)][0]\n",
    "        MPAA = [c.split(':')[1] for c in movie.data['certificates'] if (c.startswith('United States') or 'USA' in c)][0]\n",
    "    except:\n",
    "        # result['mpaa'] = pd.NA\n",
    "        MPAA = pd.NA\n",
    "\n",
    "    try:\n",
    "        # result['description'] = movie.data['plot outline']\n",
    "        description = movie.data['plot outline']\n",
    "    except:\n",
    "        # result['description'] = pd.NA\n",
    "        description = pd.NA\n",
    "\n",
    "    try:\n",
    "        # result['votes'] = movie.data['votes']\n",
    "        votes = movie.data['votes']\n",
    "    except:\n",
    "        # result['votes'] = pd.NA\n",
    "        votes = pd.NA\n",
    "\n",
    "    # print(result)\n",
    "    return (rating,genres,MPAA,description,votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_sample = basics_movies.sample(200, random_state=42).reset_index()\n",
    "# movies_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra = movies_sample['tconst'].apply(get_IMDB_movie_data)\n",
    "extra = pd.DataFrame(extra.to_list(), columns=['rating','genres','mpaa','description','votes'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_sample_big = pd.concat([movies_sample, extra], axis=1)\n",
    "# movies_sample_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rotten-tomatoes-scraper\n",
    "from rotten_tomatoes_scraper.rt_scraper import MovieScraper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RT_ratings(movie_title):\n",
    "    \"\"\"\n",
    "    Returns the Rotten Tomatoes critic score and audience score of a title\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract URL\n",
    "    RT_search = MovieScraper()\n",
    "    try:\n",
    "        search_res = RT_search.search(movie_title)\n",
    "\n",
    "        # Exact match\n",
    "        url_list = [movie_dict['url'] for movie_dict in search_res['movies']\n",
    "                    if movie_dict['name'].lower() == movie_title.lower()]\n",
    "        if len(url_list) == 1:\n",
    "            url = url_list[0]\n",
    "        # No exact match -  return the latest one\n",
    "        elif not url_list:\n",
    "            url_list = sorted([(movie_dict['url'], movie_dict['year']) for movie_dict in search_res['movies']],\n",
    "                            key=lambda x: x[1], reverse=True)\n",
    "            try:\n",
    "                url = url_list[0][0]\n",
    "            except:\n",
    "                return pd.NA, pd.NA\n",
    "            # print(f'No exact match found. Going with {url}')\n",
    "        # More than one exact match - return the latest one\n",
    "        elif len(url_list) > 1:\n",
    "            url_list = sorted([(movie_dict['url'], movie_dict['year']) for movie_dict in search_res['movies']\n",
    "                            if movie_dict['name'].lower() == movie_title.lower()],\n",
    "                            key=lambda x: x[1], reverse=True)\n",
    "            url = url_list[0][0]\n",
    "            # print(f'More than one exact match found. Going with {url}')\n",
    "\n",
    "        movie_scraper = MovieScraper(movie_url='https://www.rottentomatoes.com' + url)\n",
    "        movie_scraper.extract_metadata()\n",
    "    except:\n",
    "        return pd.NA, pd.NA\n",
    "        \n",
    "    try:\n",
    "        rt_critics_score = int(movie_scraper.metadata['Score_Rotten'])\n",
    "    except:\n",
    "        rt_critics_score = pd.NA\n",
    "\n",
    "    try:\n",
    "        rt_audience_score = int(movie_scraper.metadata['Score_Audience'])\n",
    "    except:\n",
    "        rt_audience_score = pd.NA\n",
    "        \n",
    "    return rt_critics_score, rt_audience_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_RT_ratings('The Big City')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten = movies_sample_big['primaryTitle'].apply(get_RT_ratings)\n",
    "rotten = pd.DataFrame(rotten.to_list(), columns=['rt_critics_score','rt_audience_score'])\n",
    "rotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_sample_big.to_csv('movies_sample_big.csv', index=False)\n",
    "rotten.to_csv('rotten.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the information coming from the samples, it seems that there are too many movies without important fields, so I will clean a bit the original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_movies = basics_movies.loc[(basics_movies['genres'] != '\\\\N')]\n",
    "# basics_movies = basics.loc[basics['titleType'] == 'movie']\n",
    "set_movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_movies['startYear'] = set_movies['startYear'].replace('\\\\N',0).astype('int32')\n",
    "set_movies = set_movies.loc[(set_movies['startYear'] >= 1930)]\n",
    "set_movies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I hope the scraping will have less errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_movies_sample = set_movies.sample(200, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(table):\n",
    "    extra = table['tconst'].apply(get_IMDB_movie_data) #gets extra info from imdb\n",
    "    extra = pd.DataFrame(extra.to_list(), columns=['rating','genres','mpaa','description','votes'])\n",
    "\n",
    "    rotten = movies_sample_big['primaryTitle'].apply(get_RT_ratings) # gets more ratings from rotten tomatoes\n",
    "    rotten = pd.DataFrame(rotten.to_list(), columns=['rt_critics_score','rt_audience_score'])\n",
    "    table_big = pd.concat([table, extra, rotten], axis=1)\n",
    "\n",
    "    return table_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(table):\n",
    "    table = table.reset_index()\n",
    "    extra = table['tconst'].apply(get_IMDB_movie_data) #gets extra info from imdb\n",
    "    extra = pd.DataFrame(extra.to_list(), columns=['rating','genres','mpaa','description','votes'])\n",
    "\n",
    "    rotten = movies_sample_big['primaryTitle'].apply(get_RT_ratings) # gets more ratings from rotten tomatoes\n",
    "    rotten = pd.DataFrame(rotten.to_list(), columns=['rt_critics_score','rt_audience_score'])\n",
    "    table_big = pd.concat([table, extra, rotten], axis=1)\n",
    "\n",
    "    return table_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_movies_sample_big = merge_data(set_movies_sample)\n",
    "set_movies_sample_big.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f23c331dcc0e959a18d97d72b32723b8e8fefc4a029dc171226f15b89161c30"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
